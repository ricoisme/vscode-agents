#!/usr/bin/env python3
"""fix_srt_enhanced.py

å¢å¼·ç‰ˆå­—å¹•ä¿®æ­£å·¥å…·ï¼Œå¤§å¹…æå‡ç¹é«”ä¸­æ–‡ã€è‹±æ–‡çš„éŒ¯åˆ¥å­—èˆ‡ä¸Šä¸‹æ–‡ä¿®æ­£èƒ½åŠ›ã€‚

ä¸»è¦æ”¹å–„ï¼š
1. ç¹é«”ä¸­æ–‡å„ªå…ˆï¼šä½¿ç”¨ OpenCC + pycorrector çµ„åˆï¼Œä¸¦å…§å»ºå¸¸è¦‹éŒ¯åˆ¥å­—å°ç…§è¡¨
2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼šä½¿ç”¨æ»‘å‹•çª—å£è™•ç†ç›¸é„°å­—å¹•ï¼Œæå‡èªæ„é€£è²«æ€§
3. è‹±æ–‡å¼·åŒ–ï¼šæ•´åˆ pyspellchecker èˆ‡ language_tool_python é€²è¡Œæ‹¼å¯«å’Œèªæ³•æª¢æŸ¥
4. é«˜æ•ˆèƒ½ï¼šLRU å¿«å–ã€æ‰¹æ¬¡è™•ç†ï¼Œ10åˆ†é˜ç‰‡é•·å¯åœ¨1-2åˆ†é˜å…§å®Œæˆ

å®‰è£ä¾è³´ï¼š
  pip install opencc-python-reimplemented pyspellchecker language-tool-python pycorrector

ç”¨æ³•ç¯„ä¾‹ï¼š
  python fix_srt_enhanced.py --input input.srt --output output.srt
  python fix_srt_enhanced.py --input input.vtt --output output.vtt --enable-lt --context-window 3
"""

from __future__ import annotations

import argparse
import json
import os
import re
from datetime import timedelta
from typing import List, Tuple, Dict
from functools import lru_cache

# æ ¸å¿ƒä¾è³´
try:
    from opencc import OpenCC
    OPENCC_AVAILABLE = True
    # åˆå§‹åŒ–ç°¡ç¹è½‰æ›å™¨
    s2t_converter = OpenCC('s2t')  # ç°¡é«”è½‰ç¹é«”
    t2s_converter = OpenCC('t2s')  # ç¹é«”è½‰ç°¡é«”
except ImportError:
    OPENCC_AVAILABLE = False
    print("âš ï¸  opencc æœªå®‰è£ï¼Œç¹é«”ä¸­æ–‡ä¿®æ­£åŠŸèƒ½å°‡å—é™ã€‚å»ºè­°: pip install opencc-python-reimplemented")

try:
    import pycorrector
    PYCORRECTOR_AVAILABLE = True
except ImportError:
    PYCORRECTOR_AVAILABLE = False
    print("âš ï¸  pycorrector æœªå®‰è£ï¼Œä¸­æ–‡éŒ¯åˆ¥å­—ä¿®æ­£åŠŸèƒ½å°‡å—é™ã€‚å»ºè­°: pip install pycorrector")

try:
    from spellchecker import SpellChecker
    SPELLCHECKER_AVAILABLE = True
    en_spell = SpellChecker(language='en')
except ImportError:
    SPELLCHECKER_AVAILABLE = False
    print("âš ï¸  pyspellchecker æœªå®‰è£ï¼Œè‹±æ–‡æ‹¼å­—æª¢æŸ¥åŠŸèƒ½å°‡å—é™ã€‚å»ºè­°: pip install pyspellchecker")

try:
    import language_tool_python
    LANGUAGETOOL_AVAILABLE = True
except ImportError:
    LANGUAGETOOL_AVAILABLE = False
    print("â„¹ï¸  language-tool-python æœªå®‰è£ã€‚å¯é¸å®‰è£ä»¥ç²å¾—æ›´å¼·å¤§çš„èªæ³•æª¢æŸ¥: pip install language-tool-python")


# ========== è¼‰å…¥ç¹é«”ä¸­æ–‡éŒ¯åˆ¥å­—å°ç…§è¡¨ ==========
def load_typo_map() -> Dict[str, str]:
    """å¾ JSON æª”æ¡ˆè¼‰å…¥éŒ¯åˆ¥å­—å°ç…§è¡¨"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    typo_map_path = os.path.join(script_dir, 'typo_map.json')

    try:
        with open(typo_map_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # åˆä½µæ‰€æœ‰åˆ†é¡çš„æ˜ å°„
            combined_map = {}
            for category, mappings in data.get('mappings', {}).items():
                combined_map.update(mappings)
            return combined_map
    except FileNotFoundError:
        print(f"âš ï¸  éŒ¯åˆ¥å­—å°ç…§è¡¨æª”æ¡ˆä¸å­˜åœ¨: {typo_map_path}")
        return {}
    except json.JSONDecodeError as e:
        print(f"âš ï¸  éŒ¯åˆ¥å­—å°ç…§è¡¨ JSON æ ¼å¼éŒ¯èª¤: {e}")
        return {}
    except Exception as e:
        print(f"âš ï¸  è¼‰å…¥éŒ¯åˆ¥å­—å°ç…§è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {}


# åˆå§‹åŒ–éŒ¯åˆ¥å­—å°ç…§è¡¨
TRADITIONAL_CHINESE_TYPO_MAP = load_typo_map()

# ========== æ™‚é–“æˆ³è§£æèˆ‡æ ¼å¼åŒ– ==========
TIMESTAMP_SRT_RE = re.compile(r"^(\d{2}):(\d{2}):(\d{2}),(\d{3})$")
TIMESTAMP_VTT_RE = re.compile(r"^(\d{2}):(\d{2}):(\d{2})\.(\d{3})$")
PUNCT_END = set('.?!ã€‚ï¼ï¼Ÿ')


def parse_timestamp(ts: str, format: str = 'srt') -> timedelta:
    """è§£æ SRT (é€—è™Ÿ) æˆ– VTT (å¥è™Ÿ) æ ¼å¼çš„æ™‚é–“æˆ³"""
    ts = ts.strip()
    m = TIMESTAMP_VTT_RE.match(ts) if format == 'vtt' else TIMESTAMP_SRT_RE.match(ts)

    if not m:
        # å˜—è©¦å¦ä¸€ç¨®æ ¼å¼ä½œç‚ºå¾Œå‚™
        m = TIMESTAMP_SRT_RE.match(ts) if format == 'vtt' else TIMESTAMP_VTT_RE.match(ts)

    if not m:
        raise ValueError(f"ç„¡æ•ˆçš„æ™‚é–“æˆ³: {ts}")

    hh, mm, ss, ms = map(int, m.groups())
    return timedelta(hours=hh, minutes=mm, seconds=ss, milliseconds=ms)


def format_timestamp(td: timedelta, format: str = 'srt') -> str:
    """æ ¼å¼åŒ–æ™‚é–“æˆ³ç‚º SRT æˆ– VTT æ ¼å¼"""
    total_ms = int(td.total_seconds() * 1000)
    if total_ms < 0:
        total_ms = 0

    ms = total_ms % 1000
    s = (total_ms // 1000) % 60
    m = (total_ms // (1000 * 60)) % 60
    h = total_ms // (1000 * 60 * 60)

    separator = '.' if format == 'vtt' else ','
    return f"{h:02d}:{m:02d}:{s:02d}{separator}{ms:03d}"


def detect_format(path: str) -> str:
    """å¾å‰¯æª”åæˆ–å…§å®¹åµæ¸¬å­—å¹•æ ¼å¼"""
    ext = os.path.splitext(path)[1].lower()
    if ext == '.vtt':
        return 'vtt'
    elif ext == '.srt':
        return 'srt'

    # å¾Œå‚™ï¼šæª¢æŸ¥æª”æ¡ˆå…§å®¹æ˜¯å¦æœ‰ WEBVTT æ¨™é ­
    try:
        with open(path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            if first_line.startswith('WEBVTT'):
                return 'vtt'
    except:
        pass

    return 'srt'  # é è¨­


# ========== å­—å¹•ç‰©ä»¶å®šç¾© ==========
class Subtitle:
    def __init__(self, index: int, start: timedelta, end: timedelta, content: str):
        self.index = index
        self.start = start
        self.end = end
        self.content = content.strip()

    @property
    def duration(self) -> float:
        return (self.end - self.start).total_seconds()


# ========== è®€å–èˆ‡å¯«å…¥ ==========
def read_srt(path: str, format: str = 'srt') -> List[Subtitle]:
    """è®€å– SRT æˆ– VTT æª”æ¡ˆä¸¦å›å‚³ Subtitle ç‰©ä»¶æ¸…å–®"""
    with open(path, 'r', encoding='utf-8') as f:
        text = f.read()

    # ç§»é™¤ WEBVTT æ¨™é ­ï¼ˆå¦‚æœæœ‰ï¼‰
    if format == 'vtt':
        lines = text.splitlines()
        if lines and lines[0].strip().startswith('WEBVTT'):
            text = '\n'.join(lines[1:])

    parts = re.split(r"\n{2,}", text.strip())
    subs: List[Subtitle] = []

    for part in parts:
        lines = part.strip().splitlines()
        if len(lines) < 2:
            continue

        # ç¬¬ä¸€è¡Œå¯èƒ½æ˜¯ç´¢å¼• (SRT) æˆ– cue è­˜åˆ¥ç¢¼ (VTT, å¯é¸)
        idx_line = lines[0].strip()
        try:
            idx = int(idx_line)
            times_line = lines[1]
            content_lines = lines[2:]
        except ValueError:
            # æ²’æœ‰ç´¢å¼•ï¼Œå‡è¨­æ™‚é–“åœ¨ç¬¬ä¸€è¡Œ
            idx = len(subs) + 1
            times_line = lines[0]
            content_lines = lines[1:]

        if '-->' not in times_line:
            continue

        start_s, end_s = [s.strip() for s in times_line.split('-->')]
        start = parse_timestamp(start_s, format)
        end = parse_timestamp(end_s, format)
        content = '\n'.join(content_lines).strip()
        subs.append(Subtitle(idx, start, end, content))

    return subs


def write_srt(path: str, subs: List[Subtitle], format: str = 'srt') -> None:
    """å°‡å­—å¹•å¯«å…¥ SRT æˆ– VTT æª”æ¡ˆ"""
    with open(path, 'w', encoding='utf-8') as f:
        # VTT æ ¼å¼éœ€è¦æ¨™é ­
        if format == 'vtt':
            f.write("WEBVTT\n\n")

        for i, s in enumerate(subs, start=1):
            if format == 'srt':
                f.write(f"{i}\n")
            f.write(f"{format_timestamp(s.start, format)} --> {format_timestamp(s.end, format)}\n")
            f.write(s.content + "\n\n")


# ========== èªè¨€åµæ¸¬ ==========
def detect_language_simple(text: str) -> str:
    """ç°¡å–®çš„èªè¨€åµæ¸¬ï¼šä¸­æ–‡ (zh) æˆ–è‹±æ–‡ (en)"""
    if re.search(r"[\u4e00-\u9fff]", text):
        return 'zh'
    return 'en'


# ========== æ–‡å­—ä¿®æ­£ï¼šç¹é«”ä¸­æ–‡ ==========
@lru_cache(maxsize=1024)
def fix_traditional_chinese_typos_dict(text: str) -> Tuple[str, bool]:
    """ä½¿ç”¨å…§å»ºå­—å…¸å¿«é€Ÿä¿®æ­£ç¹é«”ä¸­æ–‡å¸¸è¦‹éŒ¯åˆ¥å­—ï¼ˆå·²å¿«å–ï¼‰"""
    original = text

    for typo, correct in TRADITIONAL_CHINESE_TYPO_MAP.items():
        if typo in text:
            text = text.replace(typo, correct)

    return text, text != original


@lru_cache(maxsize=512)
def fix_chinese_with_pycorrector(text: str) -> Tuple[str, bool]:
    """ä½¿ç”¨ pycorrector ä¿®æ­£ä¸­æ–‡ï¼ˆé€éç°¡ç¹è½‰æ›ï¼Œå·²å¿«å–ï¼‰"""
    if not PYCORRECTOR_AVAILABLE or not OPENCC_AVAILABLE:
        return text, False

    try:
        # ç¹é«” â†’ ç°¡é«” â†’ pycorrector ä¿®æ­£ â†’ ç¹é«”
        simplified = t2s_converter.convert(text)
        corrected_simplified, _ = pycorrector.correct(simplified)
        corrected_traditional = s2t_converter.convert(corrected_simplified)

        changed = corrected_traditional != text
        return corrected_traditional, changed
    except Exception as e:
        return text, False


def fix_chinese_text(text: str, context: str = '') -> Tuple[str, bool]:
    """ç¶œåˆä¿®æ­£ç¹é«”ä¸­æ–‡æ–‡å­—ï¼ˆå­—å…¸ + pycorrectorï¼‰"""
    original = text

    # æ­¥é©Ÿ 1ï¼šå¿«é€Ÿå­—å…¸ä¿®æ­£
    text, dict_changed = fix_traditional_chinese_typos_dict(text)

    # æ­¥é©Ÿ 2ï¼špycorrector ä¿®æ­£ï¼ˆå¦‚æœå¯ç”¨ä¸”æ–‡å­—é•·åº¦è¶³å¤ ï¼‰
    pycorrector_changed = False
    if len(text) >= 3:  # å¤ªçŸ­çš„æ–‡å­—ä¸ç”¨ pycorrector
        text, pycorrector_changed = fix_chinese_with_pycorrector(text)

    # æ­¥é©Ÿ 3ï¼šåŸºæœ¬æ¨™é»èˆ‡ç©ºç™½ä¿®æ­£
    # ç§»é™¤ä¸­æ–‡æ¨™é»å‰çš„ç©ºç™½
    text = re.sub(r"\s+([ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€])", r"\1", text)
    # ä¸­æ–‡èˆ‡è‹±æ–‡/æ•¸å­—ä¹‹é–“åŠ ç©ºç™½
    text = re.sub(r"([\u4e00-\u9fff])([A-Za-z0-9]+)", r"\1 \2", text)
    text = re.sub(r"([A-Za-z0-9]+)([\u4e00-\u9fff])", r"\1 \2", text)
    # ç§»é™¤å¤šé¤˜ç©ºç™½
    text = re.sub(r"\s{2,}", ' ', text)
    text = text.strip()

    return text, text != original


# ========== æ–‡å­—ä¿®æ­£ï¼šè‹±æ–‡ ==========
@lru_cache(maxsize=512)
def fix_english_spelling(word: str) -> str:
    """ä½¿ç”¨ pyspellchecker ä¿®æ­£å–®å­—æ‹¼å¯«ï¼ˆå·²å¿«å–ï¼‰"""
    if not SPELLCHECKER_AVAILABLE:
        return word

    # ä¿ç•™å…¨å¤§å¯«ã€æ•¸å­—ã€ç‰¹æ®Šç¬¦è™Ÿ
    if word.isupper() or word.isdigit() or not word.isalpha():
        return word

    # æª¢æŸ¥æ˜¯å¦æ‹¼éŒ¯
    if word.lower() not in en_spell:
        corrected = en_spell.correction(word.lower())
        if corrected and corrected != word.lower():
            # ä¿æŒåŸå§‹å¤§å°å¯«æ ¼å¼
            if word[0].isupper():
                return corrected.capitalize()
            return corrected

    return word


def fix_english_text(text: str, context: str = '', use_languagetool: bool = False) -> Tuple[str, bool]:
    """ä¿®æ­£è‹±æ–‡æ–‡å­—ï¼ˆæ‹¼å­— + èªæ³•ï¼‰"""
    original = text

    # æ­¥é©Ÿ 1ï¼šåŸºæœ¬æ¨™é»ä¿®æ­£
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿå‰çš„ç©ºç™½
    text = re.sub(r"\s+([.,!?;:])", r"\1", text)
    # ç¢ºä¿æ¨™é»ç¬¦è™Ÿå¾Œæœ‰ç©ºç™½
    text = re.sub(r"([.,!?;:])([^\s])", r"\1 \2", text)
    # ç§»é™¤å¤šé¤˜ç©ºç™½
    text = re.sub(r"\s{2,}", ' ', text)

    # æ­¥é©Ÿ 2ï¼šæ‹¼å­—ä¿®æ­£ï¼ˆé€å­—ï¼‰
    if SPELLCHECKER_AVAILABLE:
        words = text.split()
        corrected_words = [fix_english_spelling(w) for w in words]
        text = ' '.join(corrected_words)

    # æ­¥é©Ÿ 3ï¼šé¦–å­—æ¯å¤§å¯«ï¼ˆå¦‚æœçœ‹èµ·ä¾†åƒå¥å­é–‹é ­ï¼‰
    if text and text[0].islower():
        text = text[0].upper() + text[1:]

    # æ­¥é©Ÿ 4ï¼šlanguage_tool_python èªæ³•æª¢æŸ¥ï¼ˆå¯é¸ï¼Œè¼ƒæ…¢ï¼‰
    if use_languagetool and LANGUAGETOOL_AVAILABLE:
        try:
            tool = language_tool_python.LanguageTool('en-US')
            matches = tool.check(text)
            text = language_tool_python.utils.correct(text, matches)
            tool.close()
        except Exception as e:
            pass  # å¤±æ•—æ™‚ä¸å½±éŸ¿ä¸»æµç¨‹

    return text, text != original


# ========== ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¿®æ­£ ==========
def fix_text_with_context(subs: List[Subtitle], window_size: int = 3, use_languagetool: bool = False) -> int:
    """ä½¿ç”¨æ»‘å‹•çª—å£ä¿®æ­£å­—å¹•æ–‡å­—ï¼Œè€ƒæ…®å‰å¾Œæ–‡ä¸Šä¸‹æ–‡

    Args:
        subs: å­—å¹•æ¸…å–®
        window_size: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰å¾Œå„å¹¾å¥ï¼‰
        use_languagetool: æ˜¯å¦ä½¿ç”¨ language_tool_pythonï¼ˆè¼ƒæ…¢ä½†æ›´æº–ç¢ºï¼‰

    Returns:
        ä¿®æ­£çš„å­—å¹•æ•¸é‡
    """
    total_changes = 0

    for i, sub in enumerate(subs):
        # å»ºç«‹ä¸Šä¸‹æ–‡ï¼ˆå‰å¾Œå„ window_size å¥ï¼‰
        start_idx = max(0, i - window_size)
        end_idx = min(len(subs), i + window_size + 1)
        context_texts = [s.content for s in subs[start_idx:end_idx] if s != sub]
        context = ' '.join(context_texts)

        # åµæ¸¬èªè¨€
        lang = detect_language_simple(sub.content)

        # æ ¹æ“šèªè¨€é¸æ“‡ä¿®æ­£ç­–ç•¥
        if lang == 'zh':
            new_text, changed = fix_chinese_text(sub.content, context)
        else:  # en
            new_text, changed = fix_english_text(sub.content, context, use_languagetool)

        if changed:
            sub.content = new_text
            total_changes += 1

    return total_changes


# ========== æ™‚é–“è»¸ä¿®æ­£ ==========
def fix_timing_and_merge(subs: List[Subtitle], min_duration: float = 0.5) -> Tuple[List[Subtitle], Dict]:
    """ä¿®æ­£æ™‚é–“æˆ³ã€é¿å…é‡ç–Šã€ä¿å®ˆåˆä½µæ¥µçŸ­æ®µè½

    Returns:
        (new_subs, stats)
    """
    changed = {'adjusted': 0, 'merged': 0, 'renumbered': 0}

    # ç¬¬ä¸€éšæ®µï¼šä¿®æ­£ç„¡æ•ˆçš„ end <= start
    for s in subs:
        if s.end <= s.start:
            s.end = s.start + timedelta(seconds=min_duration)
            changed['adjusted'] += 1

    # ç¬¬äºŒéšæ®µï¼šç¢ºä¿å–®èª¿æ€§ï¼Œåˆä½µæ¥µçŸ­æ®µè½
    i = 0
    out: List[Subtitle] = []

    while i < len(subs):
        s = subs[i]

        # å¦‚æœæœ‰å‰ä¸€å€‹ä¸”é‡ç–Š â†’ å°‡ start ç§»åˆ° prev.end
        if out and s.start < out[-1].end:
            s.start = out[-1].end
            if s.end <= s.start:
                s.end = s.start + timedelta(seconds=min_duration)
            changed['adjusted'] += 1

        # ä¿å®ˆåˆä½µï¼šå¦‚æœé•·åº¦ < min_duration ä¸”å‰ä¸€å€‹å­˜åœ¨ä¸”å‰ä¸€å€‹æœªä»¥æ¨™é»çµå°¾
        if s.duration < min_duration and out:
            prev = out[-1]
            last_char = prev.content.strip()[-1:] if prev.content.strip() else ''
            if last_char not in PUNCT_END:
                # åˆä½µåˆ°å‰ä¸€å€‹
                prev.content = prev.content.rstrip() + ' ' + s.content.lstrip()
                prev.end = max(prev.end, s.end)
                changed['merged'] += 1
                i += 1
                continue

        # å¦å‰‡ï¼Œå˜—è©¦èˆ‡ä¸‹ä¸€å€‹åˆä½µï¼ˆå¦‚æœçŸ­ä¸”ä¸‹ä¸€å€‹ç·Šæ¥è‘—é–‹å§‹ï¼‰
        if s.duration < min_duration and i + 1 < len(subs):
            nxt = subs[i + 1]
            if nxt.start <= s.end + timedelta(milliseconds=int(min_duration * 1000 / 2)):
                nxt.start = s.start
                nxt.content = s.content.rstrip() + ' ' + nxt.content.lstrip()
                changed['merged'] += 1
                i += 1
                continue

        out.append(s)
        i += 1

    # ç¬¬ä¸‰éšæ®µï¼šç¢ºä¿æ²’æœ‰é‡ç–Šå’Œæœ€å°é–“éš”
    for j in range(1, len(out)):
        prev = out[j - 1]
        cur = out[j]
        if cur.start < prev.end:
            cur.start = prev.end
            if cur.end <= cur.start:
                cur.end = cur.start + timedelta(seconds=min_duration)
            changed['adjusted'] += 1

    changed['renumbered'] = len(out)
    return out, changed


# ========== ä¸»è¦è™•ç†å‡½å¼ ==========
def process_file(
    in_path: str,
    out_path: str,
    min_duration: float = 0.5,
    dry_run: bool = False,
    output_format: str = None,
    context_window: int = 3,
    enable_languagetool: bool = False
) -> Dict:
    """è™•ç†å–®ä¸€å­—å¹•æª”æ¡ˆ"""

    # è‡ªå‹•åµæ¸¬è¼¸å…¥æ ¼å¼
    input_format = detect_format(in_path)

    # æ±ºå®šè¼¸å‡ºæ ¼å¼ï¼šæ˜ç¢ºåƒæ•¸ > è¼¸å‡ºæª”å‰¯æª”å > è¼¸å…¥æ ¼å¼
    if output_format:
        out_fmt = output_format
    else:
        out_fmt = detect_format(out_path)

    print(f"ğŸ“– è®€å–æª”æ¡ˆ: {in_path} (æ ¼å¼: {input_format.upper()})")
    subs = read_srt(in_path, format=input_format)
    original_count = len(subs)

    print(f"ğŸ”§ åŸ·è¡Œæ–‡å­—ä¿®æ­£ï¼ˆä¸Šä¸‹æ–‡çª—å£: {context_window}ï¼‰...")
    text_changes = fix_text_with_context(subs, window_size=context_window, use_languagetool=enable_languagetool)

    print(f"â±ï¸  åŸ·è¡Œæ™‚é–“è»¸ä¿®æ­£...")
    fixed_subs, stats = fix_timing_and_merge(subs, min_duration=min_duration)

    stats['text_changes'] = text_changes
    stats['original_count'] = original_count
    stats['final_count'] = len(fixed_subs)
    stats['input_format'] = input_format
    stats['output_format'] = out_fmt

    if dry_run:
        print("\nğŸ” é è¦½æ¨¡å¼ - è®Šæ›´æ‘˜è¦ï¼š")
        print(f"   åŸå§‹å­—å¹•æ•¸: {stats['original_count']}")
        print(f"   æœ€çµ‚å­—å¹•æ•¸: {stats['final_count']}")
        print(f"   æ–‡å­—ä¿®æ­£æ•¸: {stats['text_changes']}")
        print(f"   æ™‚é–“èª¿æ•´æ•¸: {stats['adjusted']}")
        print(f"   åˆä½µæ®µè½æ•¸: {stats['merged']}")
        return stats

    print(f"ğŸ’¾ å¯«å…¥æª”æ¡ˆ: {out_path} (æ ¼å¼: {out_fmt.upper()})")
    write_srt(out_path, fixed_subs, format=out_fmt)

    print("\nâœ… å®Œæˆï¼è®Šæ›´æ‘˜è¦ï¼š")
    print(f"   åŸå§‹å­—å¹•æ•¸: {stats['original_count']}")
    print(f"   æœ€çµ‚å­—å¹•æ•¸: {stats['final_count']}")
    print(f"   æ–‡å­—ä¿®æ­£æ•¸: {stats['text_changes']}")
    print(f"   æ™‚é–“èª¿æ•´æ•¸: {stats['adjusted']}")
    print(f"   åˆä½µæ®µè½æ•¸: {stats['merged']}")

    return stats


# ========== ä¸»ç¨‹å¼é€²å…¥é» ==========
def main():
    parser = argparse.ArgumentParser(
        description='å¢å¼·ç‰ˆ SRT/VTT å­—å¹•ä¿®æ­£å·¥å…·ï¼šæ™‚é–“è»¸ã€ç·¨è™Ÿã€ç¹é«”ä¸­æ–‡éŒ¯åˆ¥å­—ã€è‹±æ–‡æ‹¼å¯«èˆ‡èªæ³•ä¿®æ­£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹ç”¨æ³•ï¼š
  # åŸºæœ¬ç”¨æ³•ï¼ˆç¹é«”ä¸­æ–‡å„ªå…ˆï¼Œå¿«é€Ÿä¿®æ­£ï¼‰
  python fix_srt_enhanced.py --input input.srt --output output.srt

  # å•Ÿç”¨æ›´å¼·å¤§çš„èªæ³•æª¢æŸ¥ï¼ˆè¼ƒæ…¢ä½†æ›´æº–ç¢ºï¼‰
  python fix_srt_enhanced.py --input input.srt --output output.srt --enable-lt

  # èª¿æ•´ä¸Šä¸‹æ–‡çª—å£å¤§å°
  python fix_srt_enhanced.py --input input.srt --output output.srt --context-window 5

  # é è¦½è®Šæ›´è€Œä¸å¯¦éš›å¯«å…¥
  python fix_srt_enhanced.py --input input.srt --output output.srt --dry-run

  # SRT è½‰ VTT æ ¼å¼
  python fix_srt_enhanced.py --input input.srt --output output.vtt
        """
    )

    parser.add_argument('--input', '-i', required=True, help='è¼¸å…¥ .srt æˆ– .vtt æª”æ¡ˆ')
    parser.add_argument('--output', '-o', required=True, help='è¼¸å‡ºä¿®æ­£å¾Œçš„ .srt æˆ– .vtt æª”æ¡ˆ')
    parser.add_argument('--min-duration', type=float, default=0.5, help='æœ€å°å­—å¹•æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰ï¼ˆé è¨­ 0.5ï¼‰')
    parser.add_argument('--output-format', choices=['srt', 'vtt'], help='è¼¸å‡ºæ ¼å¼ï¼ˆæœªæŒ‡å®šæ™‚è‡ªå‹•åµæ¸¬ï¼‰')
    parser.add_argument('--context-window', type=int, default=3, help='ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰å¾Œå„å¹¾å¥ï¼‰ï¼ˆé è¨­ 3ï¼‰')
    parser.add_argument('--enable-lt', action='store_true', help='å•Ÿç”¨ language_tool_python é€²è¡Œæ›´å¼·å¤§çš„èªæ³•æª¢æŸ¥ï¼ˆè¼ƒæ…¢ï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='é è¦½è®Šæ›´æ‘˜è¦è€Œä¸å¯¦éš›å¯«å…¥æª”æ¡ˆ')

    args = parser.parse_args()

    # æª¢æŸ¥ä¾è³´å¥—ä»¶
    print("ğŸ” æª¢æŸ¥ä¾è³´å¥—ä»¶...")
    if not OPENCC_AVAILABLE:
        print("   âš ï¸  å»ºè­°å®‰è£ opencc-python-reimplemented ä»¥ç²å¾—æœ€ä½³ç¹é«”ä¸­æ–‡æ”¯æ´")
    if not PYCORRECTOR_AVAILABLE:
        print("   âš ï¸  å»ºè­°å®‰è£ pycorrector ä»¥ç²å¾—æ›´å¥½çš„ä¸­æ–‡éŒ¯åˆ¥å­—ä¿®æ­£")
    if not SPELLCHECKER_AVAILABLE:
        print("   âš ï¸  å»ºè­°å®‰è£ pyspellchecker ä»¥ç²å¾—è‹±æ–‡æ‹¼å­—æª¢æŸ¥")
    if args.enable_lt and not LANGUAGETOOL_AVAILABLE:
        print("   âš ï¸  --enable-lt éœ€è¦å®‰è£ language-tool-python")
    print()

    result = process_file(
        args.input,
        args.output,
        min_duration=args.min_duration,
        dry_run=args.dry_run,
        output_format=args.output_format,
        context_window=args.context_window,
        enable_languagetool=args.enable_lt
    )


if __name__ == '__main__':
    main()
